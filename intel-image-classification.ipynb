{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":269359,"sourceType":"datasetVersion","datasetId":111880}],"dockerImageVersionId":30301,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport torch \nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nimport os\nimport joblib\nimport glob\nfrom skimage import io\nimport random\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.densenet = models.densenet201(pretrained=True)\n        self.fc = nn.Linear(1000, 6)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        x = self.densenet(x)\n        x = self.relu(x)\n        x = self.fc(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(data.Dataset):\n    def __init__(self, mode, transform, val_size):\n        super().__init__()\n        self.transform = transform\n        self.mode = mode\n        path1 = '/kaggle/input/intel-image-classification/seg_train/seg_train/**/*.jpg'\n        path2 = '/kaggle/input/intel-image-classification/seg_test/seg_test/**/*.jpg'\n        all_paths = glob.glob(path1, recursive=True) + glob.glob(path2, recursive=True)\n        random.Random(0).shuffle(all_paths)\n        if mode == 'train':\n            self.images_paths = all_paths[0: int(len(all_paths) * (1 - val_size))]\n        elif mode == 'val':\n            self.images_paths = all_paths[int(len(all_paths) * (1 - val_size)): ]\n        self.labels_to_int = {'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n\n    def __getitem__(self, index):\n        img = io.imread(self.images_paths[index])\n        img = self.transform(img)\n        label = self.images_paths[index].split(os.sep)[-2]\n        label = self.labels_to_int[label]\n        return img.float(), label\n\n    def __len__(self):\n        return len(self.images_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.CrossEntropyLoss()\nbatch_size = 64\nlearning_rate = 0.001\nnum_epochs = 7\nval_size = 0.1\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = DenseNet()\nmodel = model.to(device)\ntrain_transform = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Resize((150, 150)),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.GaussianBlur(5),\n                                      transforms.RandomAdjustSharpness(2),\n                                      transforms.RandomAutocontrast(),\n                                      transforms.ColorJitter(brightness=0.5, hue=0.3)])\nval_transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((150, 150))])\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate)\ntrain_dataset = MyDataset('train', train_transform, val_size)\nval_dataset = MyDataset('val', val_transform, val_size)\ntrain_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = data.DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, num_epochs + 1):\n    print('epoch:', epoch)\n    model.train()\n    for samples, targets in train_loader:\n        samples = samples.to(device)\n        targets = targets.to(device)\n        preds = model(samples)\n        loss = loss_func(preds, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step() \n    \n    model.eval() \n    with torch.no_grad():\n        for mode, loader in zip(['train', 'val'], [train_loader, val_loader]):\n            epoch_loss, currect, num_samples = 0, 0, 0\n            for samples, targets in loader:\n                samples = samples.to(device)\n                targets = targets.to(device)\n                preds = model(samples)\n                loss = loss_func(preds, targets)\n                epoch_loss += loss.item() * targets.shape[0] \n                currect += (torch.argmax(preds, axis=1) == targets).sum()\n                num_samples += targets.shape[0]\n\n            epoch_loss = epoch_loss / num_samples\n            accuracy = currect / num_samples\n            print(mode, '- loss:', f'{epoch_loss:.2}', 'accuracy:', f'{accuracy:.2}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"samples, targets = next(iter(val_loader))\nsamples = samples.to(device)\npreds = model(samples)\npreds = preds.detach().cpu().numpy()\ntargets = targets.detach().cpu().numpy()\nsamples = samples.permute(0, 2, 3, 1).detach().cpu().numpy()\npreds = np.argmax(preds, axis=1)\n\nint_to_labels = {0: 'buildings', 1: 'forest', 2: 'glacier', 3: 'mountain', 4: 'sea', 5: 'street'}\n\nfor i in range(10):\n    fig, ax = plt.subplots(1)\n    ax.set_title('ground truth - ' + int_to_labels[targets[i]])\n    ax.set_xlabel('pred - ' + int_to_labels[preds[i]])\n    ax.imshow(samples[i])\n    \nfig.show()    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}