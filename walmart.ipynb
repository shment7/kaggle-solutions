{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2970526,"sourceType":"datasetVersion","datasetId":1820993}],"dockerImageVersionId":30301,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, dims):\n        super().__init__()\n        self.dims = dims\n        self.layers = nn.ModuleList()\n        for i in range(len(dims) - 1):\n            self.layers.append(nn.Linear(dims[i], dims[i + 1]))\n\n        self.activation = nn.ReLU()\n\n    def forward(self, x):\n        for i, layer in enumerate(self.layers):\n            x = layer(x)\n            if i < len(self.layers) - 1:\n                x = self.activation(x)\n        \n        if self.dims[-1] == 1:\n            return x.view(-1)\n        else:\n            return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch \nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport joblib\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyDataset(data.Dataset):\n    def __init__(self, x, y):\n        super().__init__()\n        self.x = x.to_numpy()\n        self.y = y.to_numpy()\n\n    def __getitem__(self, index):\n        sample = self.x[index]\n        target = self.y[index]\n        return torch.from_numpy(sample).float(), torch.from_numpy(np.array(target)).float()\n\n    def __len__(self):\n        return self.y.shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x = pd.read_csv('/kaggle/input/walmart-dataset/Walmart.csv')\ndf_y = df_x['Weekly_Sales']\ndf_x = df_x.drop(columns=['Weekly_Sales'])\n#pd.concat([df_x.nunique(axis=0), df_x.isna().sum(axis=0), df_x.dtypes], axis=1).rename(columns={0: 'uniques', 1:'na', 2:'type'})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_x['Store'] = df_x['Store'].astype(object)\ndf_x['Holiday_Flag'] = df_x['Holiday_Flag'].astype(object)\n\ndf_x['Date'] = pd.to_datetime(df_x['Date'])\ndf_x['day'] = df_x['Date'].dt.day\ndf_x['month'] = df_x['Date'].dt.month\ndf_x['year'] = df_x['Date'].dt.year\n\ndf_x = df_x.drop(columns=['Date'])\n\nx_train, x_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.1, random_state=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numeric_features = list(x_train.loc[:, x_train.dtypes != object])\nnumeric_encoder = StandardScaler()\nnumeric_encoder.fit(x_train.loc[:, numeric_features])\nx_train.loc[:, numeric_features] = numeric_encoder.transform(x_train.loc[:, numeric_features])\nx_test.loc[:, numeric_features] = numeric_encoder.transform(x_test.loc[:, numeric_features])\n\ncategorical_features = list(x_train.loc[:, x_train.dtypes == object])\ncat_encoder = OneHotEncoder()\ncat_encoder.fit(x_train.loc[:, categorical_features])\n\ntransformed = cat_encoder.transform(x_train.loc[:, categorical_features].to_numpy())\nohe = pd.DataFrame(transformed.toarray(), columns=cat_encoder.get_feature_names_out())\nx_train = x_train.reset_index()\nx_train = pd.concat([x_train, ohe], axis=1)\nx_train = x_train.drop(columns=categorical_features)\n\ntransformed = cat_encoder.transform(x_test.loc[:, categorical_features].to_numpy())\nohe = pd.DataFrame(transformed.toarray(), columns=cat_encoder.get_feature_names_out())\nx_test = x_test.reset_index()\nx_test = pd.concat([x_test, ohe], axis=1)\nx_test = x_test.drop(columns=categorical_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_func = nn.L1Loss()\nbatch_size = 512\nlearning_rate = 0.01\nnum_epochs = 500\ndims = [55, 512, 512, 1]\ndecay_every = 250\ndecay = 0.1\nmodel_dims = {'dims': dims}\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\nmodel = MLP(dims)\nmodel = model.to(device)\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, decay_every, gamma=decay)\ntrain_dataset = MyDataset(x_train, y_train)\ntest_dataset = MyDataset(x_test, y_test)\ntrain_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, num_epochs + 1):\n    print('epoch:', epoch)\n    model.train()\n    for samples, targets in train_loader:\n        samples = samples.to(device)\n        targets = targets.to(device)\n        preds = model(samples)\n        loss = loss_func(preds, targets)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step() \n        \n    scheduler.step()\n    model.eval() \n    with torch.no_grad():\n        for mode, loader in zip(['train', 'test'], [train_loader, test_loader]):\n            epoch_loss, rel_abs_error, num_samples = 0, 0, 0\n            for samples, targets in loader:\n                samples = samples.to(device)\n                targets = targets.to(device)\n                preds = model(samples)\n                loss = loss_func(preds, targets)\n                epoch_loss += loss.item() * targets.shape[0] \n                rel_abs_error += torch.abs((targets - preds) / targets).sum() \n                num_samples += targets.shape[0]\n\n            epoch_loss = epoch_loss / num_samples\n            rel_abs_error = rel_abs_error / num_samples\n            print(mode, '- mae:', f'{epoch_loss:.2}', 'mape:', f'{rel_abs_error:.2}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = model(torch.from_numpy(x_test.to_numpy()).float().to(device))\ntest_pred = test_pred.detach().cpu().numpy()\nmae = mean_absolute_error(test_pred, y_test)\nmape = mean_absolute_percentage_error(test_pred, y_test)\nprint('MAE:', mae)\nprint('MAPE:', mape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}