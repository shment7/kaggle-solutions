{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":32267,"sourceType":"datasetVersion","datasetId":24984}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch \nimport torch.nn as nn\nimport torch.utils.data as data\nimport torch.optim as optim\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n!pip install evaluate\n!pip install rouge-score\nimport evaluate\nfrom nltk.translate.bleu_score import corpus_bleu\nimport glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-10T14:04:48.156734Z","iopub.execute_input":"2023-12-10T14:04:48.156985Z","iopub.status.idle":"2023-12-10T14:05:38.120686Z","shell.execute_reply.started":"2023-12-10T14:04:48.156961Z","shell.execute_reply":"2023-12-10T14:05:38.119639Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Obtaining dependency information for evaluate from https://files.pythonhosted.org/packages/70/63/7644a1eb7b0297e585a6adec98ed9e575309bb973c33b394dae66bc35c69/evaluate-0.4.1-py3-none-any.whl.metadata\n  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.24.3)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.10.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.17.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.1\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.24.3)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24932 sha256=239d223c0e67a03a2d7c39828036d7862f83bfedd0eb18f229d044ccdee644e1\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score\nSuccessfully installed rouge-score-0.1.2\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"texts = []\nfor path in glob.glob('/kaggle/input/bbc-news-summary/BBC News Summary/News Articles/*/*', recursive=True):\n    with open(path, mode='r', encoding='ISO-8859-1') as file:\n        text = file.read()\n        file.close()\n        texts.append(text)\n\nsummaries = []\nfor path in glob.glob('/kaggle/input/bbc-news-summary/BBC News Summary/Summaries/*/*', recursive=True):\n    with open(path, mode='r', encoding='ISO-8859-1') as file:\n        summary = file.read()\n        file.close()\n        summaries.append(summary)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:05:38.122619Z","iopub.execute_input":"2023-12-10T14:05:38.123895Z","iopub.status.idle":"2023-12-10T14:05:56.596172Z","shell.execute_reply.started":"2023-12-10T14:05:38.123855Z","shell.execute_reply":"2023-12-10T14:05:56.595114Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(data={'text': texts, 'summary': summaries})\ndf = df.sample(frac=1)\nn = df.shape[0]\ndf_train = df.iloc[0: int(n * 0.9)]\ndf_test = df.iloc[int(n * 0.9): ]\nx_train = df_train['text'].to_list()\ny_train = df_train['summary'].to_list()\nx_test = df_test['text'].to_list()\ny_test = df_test['summary'].to_list()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:05:56.597465Z","iopub.execute_input":"2023-12-10T14:05:56.597820Z","iopub.status.idle":"2023-12-10T14:05:56.627810Z","shell.execute_reply.started":"2023-12-10T14:05:56.597794Z","shell.execute_reply":"2023-12-10T14:05:56.626850Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                   text  \\\n33    Blair backs 'pre-election budget'\\n\\nTony Blai...   \n2031  Yukos unit buyer faces loan claim\\n\\nThe owner...   \n252   UK helps raped Rwandan women\\n\\nBritain is to ...   \n1668  Stars shine on Bafta red carpet\\n\\nHollywood s...   \n2152  Israeli economy picking up pace\\n\\nIsrael's ec...   \n...                                                 ...   \n1687  Levy takes Whitbread novel prize\\n\\nOrange Pri...   \n818   Celtic unhappy over Bulgaria date\\n\\nMartin O'...   \n1509  No jail for singer Courtney Love\\n\\nSinger Cou...   \n481   England coach faces rap after row\\n\\nEngland c...   \n1435  Music man to the Oscars\\n\\nBill Conti's job of...   \n\n                                                summary  \n33    Mr Blair praised his chancellor for his role i...  \n2031  Yukos' owner Menatep Group says it will ask Ro...  \n252   The plight of the infected women was overshado...  \n1668  Keanu Reeves, who presented the best actress a...  \n2152  The main driver of the faster-than-expected ex...  \n...                                                 ...  \n1687  Orange Prize winner Andrea Levy has seen her b...  \n818   \"When we were out playing Barcelona, I spoke w...  \n1509  In a separate case relating to the same incide...  \n481   Robinson had said he was \"livid\" about Kaplan'...  \n1435  Conti's most nerve-wracking moment came during...  \n\n[2225 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>summary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33</th>\n      <td>Blair backs 'pre-election budget'\\n\\nTony Blai...</td>\n      <td>Mr Blair praised his chancellor for his role i...</td>\n    </tr>\n    <tr>\n      <th>2031</th>\n      <td>Yukos unit buyer faces loan claim\\n\\nThe owner...</td>\n      <td>Yukos' owner Menatep Group says it will ask Ro...</td>\n    </tr>\n    <tr>\n      <th>252</th>\n      <td>UK helps raped Rwandan women\\n\\nBritain is to ...</td>\n      <td>The plight of the infected women was overshado...</td>\n    </tr>\n    <tr>\n      <th>1668</th>\n      <td>Stars shine on Bafta red carpet\\n\\nHollywood s...</td>\n      <td>Keanu Reeves, who presented the best actress a...</td>\n    </tr>\n    <tr>\n      <th>2152</th>\n      <td>Israeli economy picking up pace\\n\\nIsrael's ec...</td>\n      <td>The main driver of the faster-than-expected ex...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1687</th>\n      <td>Levy takes Whitbread novel prize\\n\\nOrange Pri...</td>\n      <td>Orange Prize winner Andrea Levy has seen her b...</td>\n    </tr>\n    <tr>\n      <th>818</th>\n      <td>Celtic unhappy over Bulgaria date\\n\\nMartin O'...</td>\n      <td>\"When we were out playing Barcelona, I spoke w...</td>\n    </tr>\n    <tr>\n      <th>1509</th>\n      <td>No jail for singer Courtney Love\\n\\nSinger Cou...</td>\n      <td>In a separate case relating to the same incide...</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>England coach faces rap after row\\n\\nEngland c...</td>\n      <td>Robinson had said he was \"livid\" about Kaplan'...</td>\n    </tr>\n    <tr>\n      <th>1435</th>\n      <td>Music man to the Oscars\\n\\nBill Conti's job of...</td>\n      <td>Conti's most nerve-wracking moment came during...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2225 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class MyDataset(data.Dataset):\n    def __init__(self, text, summary, tokenizer):\n        super().__init__()\n        self.x = tokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n        self.y = tokenizer(summary, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n        self.text = text\n        self.summary = summary\n            \n    def __getitem__(self, index):\n        text_dict = {k: v[index] for k, v in self.x.items()}\n        summary_dict = {k: v[index] for k, v in self.y.items()}\n        return (text_dict, summary_dict, self.text[index], self.summary[index])\n\n    def __len__(self):\n        return self.x['input_ids'].shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:05:56.629591Z","iopub.execute_input":"2023-12-10T14:05:56.629930Z","iopub.status.idle":"2023-12-10T14:05:56.638535Z","shell.execute_reply.started":"2023-12-10T14:05:56.629903Z","shell.execute_reply":"2023-12-10T14:05:56.637555Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size = 4\nlearning_rate = 1e-4\nnum_epochs = 5\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ntokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\nmodel = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-base')    \nmodel = model.to(device)\noptimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.1)\nrouge = evaluate.load('rouge')\ntrain_dataset = MyDataset(x_train, y_train, tokenizer)\ntrain_loader = data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\ntest_dataset = MyDataset(x_test, y_test, tokenizer)\ntest_loader = data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:05:56.639811Z","iopub.execute_input":"2023-12-10T14:05:56.640174Z","iopub.status.idle":"2023-12-10T14:06:13.660101Z","shell.execute_reply.started":"2023-12-10T14:05:56.640146Z","shell.execute_reply":"2023-12-10T14:06:13.659242Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0877fa904394dfc8efb0c482682b1cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"762921c1d0184a2a9c42840c06675863"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"589893202da14f709c2f285e4367af49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c3d234722784d1eb430f628c9f3d608"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29291e047a1a4cf38794052d77a76155"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa48f2b498d2431ebbe5471eb12a6866"}},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(1, num_epochs + 1):  \n    model.train()\n    print('epoch:', epoch)\n    train_epoch_loss, train_n = 0, 0\n    for text_dict, summary_dict, text, summary in train_loader:\n        text_dict = {k:v.long().to(device) for k,v in text_dict.items()}\n        summary_dict = {k:v.long().to(device) for k,v in summary_dict.items()}\n        loss = model(**text_dict, labels=summary_dict['input_ids']).loss\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step() \n        \n    model.eval() \n    with torch.no_grad():\n        for mode, loader in zip(['train', 'test'], [train_loader, test_loader]):\n            epoch_loss, epoch_bleu_score, epoch_rouge1_score, epoch_rouge2_score, epoch_rougeL_score, num_samples = 0, 0, 0, 0, 0, 0\n            for text_dict, summary_dict, text, summary in loader:\n                text_dict = {k: v.long().to(device) for k,v in text_dict.items()}\n                summary_dict = {k: v.long().to(device) for k,v in summary_dict.items()}\n                loss = model(**text_dict, labels=summary_dict['input_ids']).loss\n                outputs = model.generate(**text_dict, max_length=50)\n                predicted_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n                bleu_score = corpus_bleu(summary, predicted_text)\n                rouge_score = rouge.compute(predictions=predicted_text, references=summary)\n                epoch_bleu_score += bleu_score * len(summary)\n                epoch_rouge1_score += rouge_score['rouge1'] * len(summary) \n                epoch_rouge2_score += rouge_score['rouge2'] * len(summary)\n                epoch_rougeL_score += rouge_score['rougeL'] * len(summary)\n                epoch_loss += loss.item() * len(summary)\n                num_samples += len(summary)\n\n            epoch_loss = epoch_loss / num_samples\n            epoch_bleu_score = epoch_bleu_score / num_samples\n            epoch_rouge1_score = epoch_rouge1_score / num_samples\n            epoch_rouge2_score = epoch_rouge2_score / num_samples\n            epoch_rougeL_score = epoch_rougeL_score / num_samples\n            print(mode, '- loss:', f'{epoch_loss:.2}')    \n            print('bleu score:', f'{epoch_bleu_score:.4}') \n            print('rouge1 score:', f'{epoch_rouge1_score:.4}') \n            print('rouge2 score:', f'{epoch_rouge2_score:.4}') \n            print('rougeL score:', f'{epoch_rougeL_score:.4}') ","metadata":{"execution":{"iopub.status.busy":"2023-12-10T14:06:13.661312Z","iopub.execute_input":"2023-12-10T14:06:13.661627Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"epoch: 1\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"name":"stdout","text":"train - loss: 0.22\nbleu score: 0.6231\nrouge1 score: 0.3733\nrouge2 score: 0.338\nrougeL score: 0.3301\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"test - loss: 0.23\nbleu score: 0.6266\nrouge1 score: 0.3693\nrouge2 score: 0.3228\nrougeL score: 0.3158\nepoch: 2\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"train - loss: 0.19\nbleu score: 0.6245\nrouge1 score: 0.3935\nrouge2 score: 0.3685\nrougeL score: 0.3519\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"test - loss: 0.23\nbleu score: 0.6254\nrouge1 score: 0.3824\nrouge2 score: 0.3423\nrougeL score: 0.3319\nepoch: 3\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"train - loss: 0.15\nbleu score: 0.6243\nrouge1 score: 0.4023\nrouge2 score: 0.3816\nrougeL score: 0.3718\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"test - loss: 0.23\nbleu score: 0.6262\nrouge1 score: 0.379\nrouge2 score: 0.3395\nrougeL score: 0.3326\nepoch: 4\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"train - loss: 0.12\nbleu score: 0.6233\nrouge1 score: 0.4075\nrouge2 score: 0.3901\nrougeL score: 0.3818\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"test - loss: 0.24\nbleu score: 0.6261\nrouge1 score: 0.392\nrouge2 score: 0.36\nrougeL score: 0.3503\nepoch: 5\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"train - loss: 0.094\nbleu score: 0.6227\nrouge1 score: 0.409\nrouge2 score: 0.3913\nrougeL score: 0.3828\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"test - loss: 0.25\nbleu score: 0.626\nrouge1 score: 0.3952\nrouge2 score: 0.3612\nrougeL score: 0.3496\nepoch: 6\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]}]}